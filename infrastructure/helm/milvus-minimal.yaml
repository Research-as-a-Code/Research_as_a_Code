# Minimal Milvus Standalone for NVIDIA RAG Blueprint
# Deploys only what's absolutely necessary: Milvus standalone, etcd, MinIO
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: milvus-data
  namespace: rag-blueprint
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: gp2-immediate
  resources:
    requests:
      storage: 20Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: etcd-data
  namespace: rag-blueprint
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: gp2-immediate
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: minio-data
  namespace: rag-blueprint
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: gp2-immediate
  resources:
    requests:
      storage: 10Gi
---
# etcd - Metadata storage
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: etcd
  namespace: rag-blueprint
spec:
  serviceName: etcd
  replicas: 1
  selector:
    matchLabels:
      app: etcd
  template:
    metadata:
      labels:
        app: etcd
    spec:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: etcd
          image: quay.io/coreos/etcd:v3.5.5
          command:
            - etcd
            - --data-dir=/etcd-data
            - --listen-client-urls=http://0.0.0.0:2379
            - --advertise-client-urls=http://etcd:2379
            - --listen-peer-urls=http://0.0.0.0:2380
            - --initial-advertise-peer-urls=http://etcd:2380
            - --initial-cluster=default=http://etcd:2380
          ports:
            - containerPort: 2379
              name: client
            - containerPort: 2380
              name: peer
          volumeMounts:
            - name: etcd-data
              mountPath: /etcd-data
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"
      volumes:
        - name: etcd-data
          persistentVolumeClaim:
            claimName: etcd-data
---
apiVersion: v1
kind: Service
metadata:
  name: etcd
  namespace: rag-blueprint
spec:
  selector:
    app: etcd
  ports:
    - port: 2379
      name: client
    - port: 2380
      name: peer
  clusterIP: None
---
# MinIO - Object storage
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: rag-blueprint
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: minio
          image: minio/minio:RELEASE.2023-03-20T20-16-18Z
          args:
            - server
            - /data
            - --console-address
            - ":9001"
          env:
            - name: MINIO_ROOT_USER
              value: "minioadmin"
            - name: MINIO_ROOT_PASSWORD
              value: "minioadmin"
          ports:
            - containerPort: 9000
              name: api
            - containerPort: 9001
              name: console
          volumeMounts:
            - name: minio-data
              mountPath: /data
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "1Gi"
      volumes:
        - name: minio-data
          persistentVolumeClaim:
            claimName: minio-data
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: rag-blueprint
spec:
  selector:
    app: minio
  ports:
    - port: 9000
      name: api
    - port: 9001
      name: console
---
# Milvus Standalone
apiVersion: apps/v1
kind: Deployment
metadata:
  name: milvus-standalone
  namespace: rag-blueprint
spec:
  replicas: 1
  selector:
    matchLabels:
      app: milvus
      component: standalone
  template:
    metadata:
      labels:
        app: milvus
        component: standalone
    spec:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: milvus
          image: milvusdb/milvus:v2.3.3
          command:
            - milvus
            - run
            - standalone
          env:
            - name: ETCD_ENDPOINTS
              value: "etcd:2379"
            - name: MINIO_ADDRESS
              value: "minio:9000"
            - name: MINIO_ACCESS_KEY_ID
              value: "minioadmin"
            - name: MINIO_SECRET_ACCESS_KEY
              value: "minioadmin"
          ports:
            - containerPort: 19530
              name: grpc
            - containerPort: 9091
              name: metrics
          volumeMounts:
            - name: milvus-data
              mountPath: /var/lib/milvus
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
          livenessProbe:
            httpGet:
              path: /healthz
              port: 9091
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /healthz
              port: 9091
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: milvus-data
          persistentVolumeClaim:
            claimName: milvus-data
---
apiVersion: v1
kind: Service
metadata:
  name: milvus-standalone
  namespace: rag-blueprint
  labels:
    app.kubernetes.io/name: milvus
spec:
  selector:
    app: milvus
    component: standalone
  ports:
    - port: 19530
      name: grpc
      protocol: TCP
    - port: 9091
      name: metrics
      protocol: TCP
  type: ClusterIP

