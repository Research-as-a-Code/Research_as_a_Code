# SPDX-FileCopyrightText: Copyright (c) 2025 Research_as_a_Code Project
# SPDX-License-Identifier: Apache-2.0

# Karpenter NodePool for GPU instances
# This will auto-provision g5.xlarge or g5.2xlarge instances when NIMs request GPUs

apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: nvidia-nim-gpu
spec:
  template:
    metadata:
      labels:
        workload-type: nvidia-nim
        node.kubernetes.io/instance-type: g5
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - g5.xlarge    # 1x NVIDIA A10G (24GB) - Good for embedding NIM
            - g5.2xlarge   # 1x NVIDIA A10G (24GB) - Good for single NIM
            - g5.4xlarge   # 1x NVIDIA A10G (24GB) - Good for Nemotron
            - g5.12xlarge  # 4x NVIDIA A10G (96GB) - For multi-NIM on single node
      nodeClassRef:
        name: nvidia-nim
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
  limits:
    cpu: "1000"
    memory: 1000Gi
  disruption:
    consolidationPolicy: WhenUnderutilized
    expireAfter: 720h

---
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: nvidia-nim
spec:
  amiFamily: AL2
  role: "KarpenterNodeRole-aiq-udf-eks"  # Update with actual role name from Terraform
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "aiq-udf-eks"  # Must match cluster name
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "aiq-udf-eks"
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 200Gi
        volumeType: gp3
        encrypted: true
        deleteOnTermination: true
  userData: |
    #!/bin/bash
    echo "Karpenter node provisioned for NVIDIA NIMs"
    # Additional GPU node setup can go here

