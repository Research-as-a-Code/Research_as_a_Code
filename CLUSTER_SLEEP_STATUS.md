# Cluster Sleep Status

**Date**: November 9, 2025  
**Status**: âœ… **SLEEPING** (Cost-saving mode)

---

## ğŸ’¤ What's Sleeping:

- âœ… All AI Agent pods (backend + frontend)
- âœ… All NIM pods (Nemotron, embedding models)
- âœ… All GPU nodes (deleted - **no GPU costs!**)
- âœ… RAG services (scaled down)

## ğŸƒ What's Still Running:

- âœ… EKS control plane (required, ~$0.10/hour)
- âœ… Karpenter (auto-scaler)
- âœ… GPU Operator (lightweight)
- âœ… 2x CPU-only nodes (system services)

---

## ğŸ’° Current Costs:

| Component | Cost/Hour | Cost/Day |
|-----------|-----------|----------|
| EKS Control Plane | $0.10 | $2.40 |
| CPU Nodes (2x t3.medium) | $0.08 | $1.92 |
| **TOTAL** | **~$0.18** | **~$4.32** |

**Savings**: ~$3-5/hour (GPU nodes stopped) = **~$72-120/day saved!** ğŸ‰

---

## â˜€ï¸ To Wake Up Tomorrow:

### Quick Start (5-10 minutes):
```bash
cd /home/csaba/repos/AIML/Research_as_a_Code
./scripts/wake-cluster.sh
```

This will:
1. Scale up all deployments
2. Karpenter will auto-provision GPU nodes (~3-5 min)
3. Pods will start (~2-5 min)
4. NIMs will load models (~5-10 min)
5. Display service URLs when ready

### Manual Alternative:
```bash
# Scale up agent
kubectl scale deployment aiq-agent-backend --replicas=2 -n aiq-agent
kubectl scale deployment aiq-agent-frontend --replicas=2 -n aiq-agent

# Scale up NIMs
kubectl scale deployment instruct-llm-nim --replicas=1 -n nim

# Watch nodes being provisioned
kubectl get nodes -w

# Get URLs when ready
kubectl get svc -n aiq-agent
```

---

## ğŸ¯ What Was Accomplished Today:

### âœ… Fixed Critical Bugs:
1. **Nemotron JSON parsing** - Model didn't output `</think>` tags
2. **Web search not triggered** - Empty collection logic fixed
3. **Citations missing** - Tavily score filter bug (score field doesn't exist)
4. **Generic responses** - Request parameters not passed to agent
5. **Chinese responses** - Language enforcement in prompts
6. **TypedDict access** - Fixed object vs dict attribute access

### âœ… Current System Status:
- âœ… **Web Search**: WORKING with Tavily API
- âœ… **Citations**: WORKING (URLs displayed)
- âœ… **English responses**: WORKING
- âœ… **Nemotron model**: DEPLOYED (Nemotron-Nano-8B on g5.xlarge)
- âŒ **RAG**: NOT WORKING (Milvus metadata issue)

### ğŸ“Š Test Results:
**Query**: "What are typical import duties for electronics from China?"
- âœ… English response
- âœ… Web search executed (Tavily)
- âœ… Citations with URLs
- âŒ RAG collection empty (requires official Blueprint deployment)

---

## ğŸ“ TODO Tomorrow:

### High Priority:
1. **Deploy Official NVIDIA RAG Blueprint** (Option A)
   - Clone: https://github.com/NVIDIA-AI-Blueprints/rag
   - Deploy using their Helm/K8s manifests
   - Properly initializes Milvus with metadata collections
   - Re-ingest tariff PDFs using official API

2. **Update Agent Backend**
   - Point to new RAG service endpoints
   - Test end-to-end with `us_tariffs` collection

3. **Final Testing**
   - Verify tariff queries return specific data + citations
   - Confirm system is hackathon-ready

### Timeline Estimate:
- Wake cluster: 10 minutes
- Deploy RAG Blueprint: 20-30 minutes
- Ingest tariffs: 10 minutes
- Testing: 10 minutes
- **Total: ~1 hour**

---

## ğŸ”— Quick Reference:

### Service URLs (when awake):
- Frontend: `http://af2f4f77d44fb4b41bc00856345951e2-974749261.us-west-2.elb.amazonaws.com`
- Backend: `http://a6a208f0a4b5e4906867c6947616b0e8-1067156064.us-west-2.elb.amazonaws.com`

### Key Files:
- Wake script: `./scripts/wake-cluster.sh`
- Sleep script: `./scripts/sleep-cluster.sh`
- Deploy agent: `./infrastructure/kubernetes/deploy-agent.sh`
- Deploy NIMs: `./infrastructure/kubernetes/deploy-nims.sh`

### AWS Region:
- `us-west-2` (GPU quota available)

### Models Deployed:
- Reasoning/Instruct: `nvidia/llama-3.1-nemotron-nano-8b-v1`
- Embedding: `nvcr.io/nim/nvidia/nemo-retriever-embedding-microservice:1.0.1`

---

## ğŸ“š Documentation Created:
- `WEB_SEARCH_BUG_FIX.md` - Web search logic fix
- `ROOT_CAUSE_ANALYSIS_TYPEDDICT_FIX.md` - TypedDict bug fix
- `CRITICAL_BUG_REQUEST_PARAMS_FIX.md` - Request params fix
- `FINAL_DEPLOYMENT_SUCCESS.md` - Deployment summary
- Multiple other diagnostic docs in root directory

---

**Sleep well! ğŸ˜´ Your cluster is saving money while you rest!**

